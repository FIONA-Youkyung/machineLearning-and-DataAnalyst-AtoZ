{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 기사 분석2 -기사 텍스트 정제\n",
    "## konply 형태소 분석기 성능 비교\n",
    ": 어떤 텍스트 데이터가 있을 때, 어떤 형태소 분석기를 사용하는 것이 적절한지를 \n",
    "#### 목표) \n",
    "- 형태소 분석기 들이 어떤 특징이 있고, \n",
    "- 얼마나 성능 차이가 나는지 \n",
    "\n",
    "#### 방법)\n",
    "- jupyter notebook으로 형태소 분석기를 사용하는 방법\n",
    "- 형태소 분석기에 따른 실행결과를 비교하는 법을 배워보자 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import\n",
    ": from konlpy.tag import ______ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma #K대문자 ! 조심\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Mecab #윈도우의 경우는, import Mecab\n",
    "from konlpy.tag import Okt #Okt는 Twitter라는 형태소분석기와 같은 버전이다. SNS와 이름 혼동 할 까봐로 Okt로 바꾸었다고 함.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석을 하기위한 객체 생성(생성자)를 만들어서 사용해야 한다. 무조건! 형태소 분석을 할 수 있는 기반을 마련해야 한다 \n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "hannanum = Hannanum()\n",
    "mecab = Mecab()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문장 분석 품질 비교\n",
    ": 문장을 어떻게 형태소 분석을 할 것이냐 , 형태소 분석의 결과가 어떻게 나오느냐 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기준1. 띄어쓰기가 제대로 되어있지 않는 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"서울시장애인복지회\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울시', 'NNG'), ('장애', 'NNG'), ('이', 'VCP'), ('ㄴ', 'ETD'), ('복지회', 'NNG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kkma 형태소 분석 결과\n",
    "kkma.pos(text) #pos : part of speech의 약자 품사정보를 준다.  #kkma.pos(text) : text의 품사정보를 볼 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서울시', '장애', '이', 'ㄴ', '복지회']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#morphs : 형태소 정보 없이 나눠지는 것만 보여준다. \n",
    "kkma.morphs(text) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울시', 'NNP'), ('장애인', 'NNP'), ('복지회', 'NNG')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Komoran 형태소 분석 결과\n",
    "komoran.pos(text) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울시장애인복지회', 'N')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hannanum 형태소 분석 결과\n",
    "hannanum.pos(text) #띄어쓰기에 굉장히 취약하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울시', 'NNP'), ('장애', 'NNG'), ('인', 'VCP+ETM'), ('복지', 'NNG'), ('회', 'NNG')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mecab 형태소 분석 결과\n",
    "mecab.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울시장', 'Noun'), ('애인', 'Noun'), ('복지', 'Noun'), ('회', 'Noun')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Okt 형태소 분석 결과\n",
    "okt.pos(text) #okt의 단점 : 품사 분석시, 명사 동사 부사 형용사 정도 밖에 안 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기준2. 오탈자 때문에 불완전한 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"ㄱㅐㄴㅏ리가 피어있는 동산에 누워있고싶ㄷㅏ\" #초 중성이 떨어져있고,, 이런 오탈자 때문에 불완전한 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkma 분석 결과 :  [('ㄱㅐㄴㅏ리', 'UN'), ('가', 'JKS'), ('피', 'VV'), ('어', 'ECD'), ('있', 'VXV'), ('는', 'ETD'), ('동산', 'NNG'), ('에', 'JKM'), ('눕', 'VV'), ('어', 'ECS'), ('있', 'VV'), ('고', 'ECE'), ('싶ㄷㅏ', 'UN')] \n",
      "\n",
      "komoran 분석 결과 :  [('개나리', 'NNP'), ('가', 'JKS'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNP'), ('에', 'JKB'), ('눕', 'VV'), ('어', 'EC'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('다', 'EC')] \n",
      "\n",
      "hannanum 분석 결과 :  [('ㄱㅐㄴㅏ리', 'N'), ('가', 'J'), ('피', 'P'), ('어', 'E'), ('있', 'P'), ('는', 'E'), ('동산', 'N'), ('에', 'J'), ('누워있고싶ㄷㅏ', 'N')] \n",
      "\n",
      "mecab 분석 결과 :  [('ㄱ', 'NNG'), ('ㅐㄴㅏ리가', 'UNKNOWN'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNG'), ('에', 'JKB'), ('누워', 'VV+EC'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('ㄷ', 'NNG'), ('ㅏ', 'UNKNOWN')] \n",
      "\n",
      "okt 분석 결과 :  [('ㄱㅐㄴㅏ', 'KoreanParticle'), ('리가', 'Noun'), ('피어있는', 'Verb'), ('동산', 'Noun'), ('에', 'Josa'), ('누워있고싶', 'Verb'), ('ㄷㅏ', 'KoreanParticle')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"kkma 분석 결과 : \" ,kkma.pos(text2), \"\\n\") \n",
    "print(\"komoran 분석 결과 : \", komoran.pos(text2), \"\\n\") \n",
    "#아래의 결과로 보았을 때, komoran이 오탈자가 있는경우, 분리되어 있는 경우 합쳐주는 기능이 있어서 이 경우에 komoran사용이 좋겠다는 걸 알 수 있다. \n",
    "print(\"hannanum 분석 결과 : \", hannanum.pos(text2), \"\\n\")\n",
    "print(\"mecab 분석 결과 : \", mecab.pos(text2), \"\\n\")\n",
    "print(\"okt 분석 결과 : \", okt.pos(text2), \"\\n\") #koreanParticle : 애매한데, 한글인 거 같애! 라는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기준3. 속도 비교\n",
    ": 데코레이터 중에서 (데코레이터가 뭔지 몰라서 찾아봤는데 설명 잘 되어있던 : https://bluese05.tistory.com/30) %%time을 셀의 맨 위에 써주면, 밑에 있는 코드들을 실행하는데 얼마나 시간이 걸렸는지 표시해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"\"\"과학기술정보통신부 유럽, 일본, 미국 등 주요 국가는 수년 전 부터 인공지능(AI) 관련 저작권 논의를 시작했다.\n",
    "이들 국가는 AI가 발전하기 위해서는 빅데이터 등과 관련된 저작권 문제를 빨리 해결해야 한다고 인식했다. \n",
    "AI는 빅데이터를 소재로 머신러닝과 딥러닝 방식의 학습을 통해 특정한 결과를 구현하는 기술이다. \n",
    "이를 위해 데이터를 수집, 저장 처리하는 과정에서 데이터 복제, 전송 등의 과정이 필요하다. \n",
    "빅데이터를 분석해 통계적 규칙, 경향 등 가치있는 정보를 찾아내는 것을 텍스트 및 데이터 마이닝(TDM)이라고 한다. \n",
    "TDM 분석 대상인 데이터에 타인의 저작물이 포함되면 저작권 침해 문제가 발생할 수 있다. 빅데이터 활용을 제한하는 요소다. \n",
    "저작물을 활용하기 위해서는 저작권자의 동의를 받아야 하지만 빅데이터에 포함된 모든 저작권자에게 일일이 동의받는 것은 사실상 불가능하다. \n",
    "엄청난 시간과 비용이 소모되기 때문이다. 영국, 프랑스, 독일 등 유럽 주요 국가들은 이런 문제를 일찍 인식했다. \n",
    "2014년 영국을 시작으로 저작권법 등 관련법에 TDM 특별규정을 도입했다. \n",
    "나라마다 내용은 차이가 있으나 공통적인 것은 '비상업적 연구 목적' TDM의 경우 저작권자 동의 없이도 저작물을 활용할 수 있도록 한다는 점이다. \n",
    "유럽연합(EU)은 올해 4월 '디지털 단일시장에서의 저작권에 관한 유럽의회 및 위원회 지침 2019/790'에 따라 TDM을 위한 입법지침을 마련했다.\n",
    "타인의 저작물을 활용한 TDM은 학문적 연구 목적 또는 문화유산기구의 활동을 보장하기 위한 목적으로 허용된다. TDM을 위해 제작된 저작물의 복제물 등은 보안조치를 취한 후 저장할 수 있다. 학문적 연구를 위해서도 계속 보유할 수 있다. \n",
    "회원국은 동 지침 제 29조에 따라 오는 2021년 6월 7일까지 자국법을 개정해야 한다. 프랑스, 독일 등 일부 회원국은 동 지침 제정 이전에 관련법을 개정해서 TDM을 허용하고 있다. \n",
    "지침 제정은 TDM에 대한 유럽의 통일적 기준이 마련됐다는 점에서 의미를 갖는다. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('과학', 'NNG'), ('기술', 'NNG'), ('정보', 'NNG'), ('통신', 'NNG'), ('부', 'NNG')]\n",
      "CPU times: user 19.1 s, sys: 874 ms, total: 19.9 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(kkma.pos(text3)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('과학기술', 'NNP'), ('정보', 'NNP'), ('통신부', 'NNG'), ('유럽', 'NNP'), (',', 'SP')]\n",
      "CPU times: user 370 ms, sys: 6.79 ms, total: 377 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(komoran.pos(text3)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('과학기술정보통신부', 'N'), ('유럽,', 'N'), ('일본', 'N'), (',', 'S'), ('미국', 'N')]\n",
      "CPU times: user 366 ms, sys: 7.22 ms, total: 373 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(hannanum.pos(text3)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('과학', 'NNG'), ('기술', 'NNG'), ('정보', 'NNG'), ('통신부', 'NNG'), ('유럽', 'NNP')]\n",
      "CPU times: user 7.41 ms, sys: 56.4 ms, total: 63.8 ms\n",
      "Wall time: 377 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(mecab.pos(text3)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('과학기술', 'Noun'), ('정보통신부', 'Noun'), ('유럽', 'Noun'), (',', 'Punctuation'), ('일본', 'Noun')]\n",
      "CPU times: user 703 ms, sys: 14.5 ms, total: 718 ms\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(okt.pos(text3)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 총정리\n",
    "- 기준1. 띄어쓰기가 제대로 되어있지 않은 문장\n",
    "    - mecab이 분류가 잘되는 편, hannanum이 분류 거의 안됨\n",
    "- 기준2. 오탈자 때문에 불완전한 문장\n",
    "    - komoran을 쓰면 초중종성 합쳐서 표시해준다. \n",
    "- 기준3. 속도\n",
    "    - kkma가 많이 느리고, mecab이 많이 빠르고, 나머지는 비슷하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
