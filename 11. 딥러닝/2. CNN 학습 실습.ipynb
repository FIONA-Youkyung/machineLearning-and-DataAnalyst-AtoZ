{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN 학습 실습\n",
    "1. 모듈 불러오기\n",
    "2. 하이퍼 파라미터 정의\n",
    "3. CNN 구조 정의\n",
    "4. 데이터 불러오기 \n",
    "    - 데이터 : keras에서 제공하는 fashion_mnist\n",
    "5. 모델 생성\n",
    "6. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크 구조 정의 (CNN 구조 정의)\n",
    "- keras방식으로 해보겠다.\n",
    "    - **convolution**(*Conv2D*)\n",
    "        - **padding** : 'same'으로 하면 padding을 하여 크기 유지, 'valid'으로 하면 zero pading하지 않고 영상이 점점 줄어든다. \n",
    "        - **activation function** : 'relu'\n",
    "    \n",
    "    - **pooling**(*MaxPool2D*) : 아무 설정도 하지 않으면 자동으로 stride:(2, 2)로 해준다. \n",
    "    - **full connection**\n",
    "         - **Flatten**\n",
    "         - **Dense**\n",
    "             - **activation function으로 classification** : 'relu', 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    return Sequential([Conv2D(32, (3, 3), padding = 'same', activation='relu'), #28*28*32\n",
    "                MaxPool2D(),#14*14*32\n",
    "                Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),#14*14*64\n",
    "                MaxPool2D(), #7*7*64\n",
    "                Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),#7*7*128\n",
    "                                \n",
    "                Flatten(),#7*7*128 => 6272\n",
    "                Dense(128, activation= 'relu'), #6272 => 128, relu\n",
    "                Dense(10, activation= 'softmax')  #128 ->10, softmax\n",
    "                ]) #순서대로 우리가 사용할 layer을 다 넣어주면 된다.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 불러오기, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train, test set split\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#흑백 영상은 각 픽셀이 0~1 사이의 실수로 된 2-D signal로 표현 할 수 있다. \n",
    "#이차원 신호와 흑백 이미지: 0~255 사이의 값을 0~1로 normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)#(x_train총 개수, heigt, width)\n",
    "print(x_train[0].shape) #(height, width)\n",
    "\n",
    "#근데 Cin(Cannel in)이 필요하니까 차원 하나를 추기해 주어야 한다. \n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "print(x_train.shape)\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds =  tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy', \n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 111s 59ms/step - loss: 0.3828 - accuracy: 0.8621 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.2467 - accuracy: 0.9092 - val_loss: 0.2524 - val_accuracy: 0.9080\n",
      "Epoch 3/10\n",
      "1108/1875 [================>.............] - ETA: 36s - loss: 0.2094 - accuracy: 0.9222"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
