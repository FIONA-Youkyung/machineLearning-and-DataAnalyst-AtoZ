{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 품질 관리 직무\n",
    "\n",
    "    - 품질 경영(QM)\n",
    "    - 품질 관리(QC) -> 품질 검사\n",
    "        - 특히 공정에서 이루어 지는 공정검사 ) \n",
    "             - 측정 -> 측정오차 리스크 있음------------------------------> 머신 비전으로 해결 : 주로 영상처리와 컴퓨터 비전 기술을 상요해 형태 분석과 측정을 한다. \n",
    "             - 육안검사 -> 작업자 실수 리스크----------------------------> 머신 비전으로 해결\n",
    "             - 기록 -> 기록 실수 리스크---------------------------------->공정 자동화로 해결\n",
    "             - 검사 기기 세팅 -> 잘못된 기기 세팅, 검사 기기 오동작--------> 공정 자동화로 해결\n",
    "            \n",
    "    - 품질 보증(QA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝\n",
    " : 빅데이터 -> End-to-end 딥러닝 모델 -> Grountruth label 을 할 때는 입출력이 잘 정의 되어있고, 학습할 데이터가 충분하다는 가정 하에 딥러닝을 진행 한 것이다. \n",
    " \n",
    " 하지만, 현실을 이렇지 않다. \n",
    " 공정 검사에서 \n",
    " ### 딥러닝 적용의 어려움\n",
    " - 빠른 변화\n",
    "     - 빠른 시장의 변화 : 시장의 변화에 맞추어 다품종 소량생산이 많아지면서, 신규 제품을 취급하는 일이 늘어남\n",
    "     - 고객의 변화 : 고객의 요구사항은 수시로 변할 수 있다. \n",
    "     - 환경의 변화 : 제품 생산 환경, 공정 검사 Software 개발 환경은 예상치 못하게 변화 할 수 있음\n",
    " - 양산 초기 품질의 확보\n",
    "     - 새로운 제품을 시장에 출시할 때에는 초기 출시 단계에서 물량을 확보하는 것이 중요\n",
    "     - 초기 물량 확보를 위해서는 초기 시작 제품의 품질 Issue를 해결하여 수율을 확보하는 것이 핵심\n",
    "     - 초기 품질을 확보하는 것 뿐 아니라, 초기 출하 제품의 품질을 확보하는 것 역시 매우 중요함 \n",
    " - 데이터 확보의 어려움\n",
    "     - 양산 다계에 있는 제품의 경우, 양산 중이 ㄴ공정에서 필요한 데이터를 확보하기 쉽지 않음\n",
    "     - 불량률이 0.1% 이하로 매우 낮은 제품군의 경우에는 다양한 불량품 데이터를 제공받기 매우 어려움\n",
    "     - 수 많은 양산 데이터가 있더라도 잘 분류된 정답 label을 포함한 질 좋은 데이터는 확보가 어려움\n",
    "     \n",
    "### 딥러닝 적용의 해결방법 및 근거\n",
    "- Domain Knowledge의 활용하여\n",
    "    - End-to-end문제가 아닌 할 수 있는 최대한의 전처리는 모두 다 해주고, 최대한 학습하기 좋은 형태로 데이터를 가공, \n",
    "    - 출력도 최종 출력을 한번에 뽑아내려 하지 말고, 중간의 출력에 Domain Knowledge를 이용한 알고리즘을 한 번 더 적용한다. \n",
    "    - 딥러닝의 관심적인 모델이 아닌, 데이터와 현상에 기반한 적합한 well-defined모델을 이용하여 문제를 해결한다.\n",
    "    - 무조건 많은 데이터가 아닌 섬세하게 확보한 적정 수준의 데이터를 이용하여 목적을 달성 할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공정 분석 딥러닝 실무\n",
    "#### 그래서 이번 학습에서는 가상고객 한 분을 설정해서, 그 가상 고객과 커뮤니케이션하면서 공동으로 원하는 무언가를 만들어보고자 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 딥러닝 실무 개요\n",
    "#### 1) 문제 정의하기 2) 스펙 결정하기  3) 실행 가능성 확인하기  4) 알고리즘 설계하기  5) 데이터 정리하기  6) 모델 학습 및 검증하기 7) 프로그램 전달하기\n",
    "## 2. 가상의 고객 설정\n",
    ": 고객이란 누구를 말하는 걸까? 누구를 위해 일하느냐는 매우 중요하다. 고객의 '요구 사항'을 만족해야 하기 때문이다. \n",
    "\n",
    "가상고객 \n",
    "이름 : 정현정 \n",
    "특징 : - 원단 사업부 제조 공정 엔지니어\n",
    "        - 제조 통계에 익숙하며, 인공지능 도입은 처음\n",
    "        - 원단에 대한 도메인 지식이 뛰어남\n",
    "        - 제조 공정에 자주 드나들어 연락이 어려움\n",
    "## 3. 데이터셋\n",
    ": 최근 aitex 사 에서 공개한 Fabric Image Dataset을 사용한다. 데이터셋을 상황에 맞게 조작한 것을 사용할 것이다. http://www.aitex.es/afid\n",
    "\n",
    "출처  : AFID: a  public fabric image database for defect detection.\n",
    "Javier Silvestre-Blanes, Teresa Albero-Albero, Ignacio Miralles, Rubén Pérez-Llorens, Jorge Moreno\n",
    "AUTEX Research Journal, No. 4, 2019     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #computer vision library\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DEFECT = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/Defect_images/'\n",
    "PATH_MASK = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/Mask_images'\n",
    "PATH_NODEFECT = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/NODefect_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0) #동일한 결과를 얻을 수 있게 random.seed를 고정\n",
    "\n",
    "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
    "mask_list =glob.glob(PATH_MASK + '*.png')\n",
    "pass_list = glob.glob(PATH_NODEFECT + '*.png')\n",
    "\n",
    "#defect, mask 데이터를 쌍으로 묶어주는 작업을 진행\n",
    "new_defect_list = list()\n",
    "new_mask_list = list()\n",
    "for defect in defect_list :\n",
    "    num = defect.splot('/')[-1].split('_')[0]\n",
    "    for mask in mask_list :\n",
    "        num_mask = mask.split[-1].split('_')[0]\n",
    "        if num == num_mask:\n",
    "            new_defect_list.append(defect)\n",
    "            new_mask_list.append(mask)\n",
    "            break\n",
    "            \n",
    "defect_list = new_defect_list\n",
    "mask_list = new_mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 발송 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set을 진행하면서 여러번 데이터를 취득하게 될 텐데 데이터를 얻는 과정을 나누어보면\n",
    "#The first dataset given\n",
    "if os.path.exists('/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/1') is False:\n",
    "    os.mkdir('/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/1')\n",
    "for file_name in pass_list+defect_list:\n",
    "    if random.randint(0, 9) <2:\n",
    "        barcode = ''. join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "        shutil.copy(file_name, '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset1/'+barcode+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 번째 데이터 생생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second dataset\n",
    "if os.path.exists('dataset/2') is False: \n",
    "    os.mkdir('dataset/2')\n",
    "if os.path.exist('dataset/2/OK') is False:\n",
    "    os.mkdir('dataset/2/OK')\n",
    "if os.path.exists('dataset/2/FAIL') is False:\n",
    "    os.mkdir('dataset/2/FAIL')\n",
    "    \n",
    "idx = 0\n",
    "\n",
    "for file_name in pass_list: #pass_list = glob.glob(PATH_NODEFECT + '*.png')의 이미지를 하나씩 \n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height//2\n",
    "    \n",
    "    for i in range(width//step):\n",
    "        w = i * step\n",
    "        if w<width - height and random.randint(0, 9) <2:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/2/OK/%04d.png' % idx,patch)\n",
    "            idx += 1\n",
    "            \n",
    "patch_list = list()\n",
    "for item in zip(defect_list, mask_list): #그 다음은 defect_list와 mask_list \n",
    "    defect, mask =. tem\n",
    "    \n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    \n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_list.append(patch)\n",
    "\n",
    "random.shuffle(patch_list)\n",
    "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
    "for idx, patch in enumerate(patch_list_fraction):\n",
    "    cv2.imwrite('dataset/2/FAIL/%04d.png' % idx, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세 번째 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third dataset\n",
    "if os.path.exists('dataset/3') is False:\n",
    "    os.mkdir('dataset/3')\n",
    "if os.path.exists('dataset/3/OK') is False:\n",
    "    os.mkdir('dataset/3/OK')\n",
    "if os.path.exists('dataset/3/FAIL') is False:\n",
    "    os.mkdir('dataset/3/FAIL')\n",
    "if os.path.exists('dataset/3/MASK') is False:\n",
    "    os.mkdir('dataset/3/MASK')\n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 3:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/3/OK/%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/3/FAIL/%04d.png' % idx, patch)\n",
    "    cv2.imwrite('dataset/3/MASK/%04d.png' % idx, patch_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실전 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test dataset\n",
    "if os.path.exists('dataset/input_data') is False:\n",
    "    os.mkdir('dataset/input_data')\n",
    "if os.path.exists('dataset/output_csv') is False:\n",
    "    os.mkdir('dataset/output_csv')\n",
    "    \n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 5:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/input_data/ok_%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/input_data/fail_%04d.png' % idx, patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
