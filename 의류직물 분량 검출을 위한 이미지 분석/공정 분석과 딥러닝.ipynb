{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 품질 관리 직무\n",
    "\n",
    "    - 품질 경영(QM)\n",
    "    - 품질 관리(QC) -> 품질 검사\n",
    "        - 특히 공정에서 이루어 지는 공정검사 ) \n",
    "             - 측정 -> 측정오차 리스크 있음------------------------------> 머신 비전으로 해결 : 주로 영상처리와 컴퓨터 비전 기술을 상요해 형태 분석과 측정을 한다. \n",
    "             - 육안검사 -> 작업자 실수 리스크----------------------------> 머신 비전으로 해결\n",
    "             - 기록 -> 기록 실수 리스크---------------------------------->공정 자동화로 해결\n",
    "             - 검사 기기 세팅 -> 잘못된 기기 세팅, 검사 기기 오동작--------> 공정 자동화로 해결\n",
    "            \n",
    "    - 품질 보증(QA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝\n",
    "(https://www.tensorflow.org/tutorials/keras/classification?hl=ko 참고)\n",
    " : 빅데이터 -> End-to-end 딥러닝 모델 -> Grountruth label 을 할 때는 입출력이 잘 정의 되어있고, 학습할 데이터가 충분하다는 가정 하에 딥러닝을 진행 한 것이다. \n",
    " \n",
    " 하지만, 현실을 이렇지 않다. \n",
    " 공정 검사에서 \n",
    " ### 딥러닝 적용의 어려움\n",
    " - 빠른 변화\n",
    "     - 빠른 시장의 변화 : 시장의 변화에 맞추어 다품종 소량생산이 많아지면서, 신규 제품을 취급하는 일이 늘어남\n",
    "     - 고객의 변화 : 고객의 요구사항은 수시로 변할 수 있다. \n",
    "     - 환경의 변화 : 제품 생산 환경, 공정 검사 Software 개발 환경은 예상치 못하게 변화 할 수 있음\n",
    " - 양산 초기 품질의 확보\n",
    "     - 새로운 제품을 시장에 출시할 때에는 초기 출시 단계에서 물량을 확보하는 것이 중요\n",
    "     - 초기 물량 확보를 위해서는 초기 시작 제품의 품질 Issue를 해결하여 수율을 확보하는 것이 핵심\n",
    "     - 초기 품질을 확보하는 것 뿐 아니라, 초기 출하 제품의 품질을 확보하는 것 역시 매우 중요함 \n",
    " - 데이터 확보의 어려움\n",
    "     - 양산 다계에 있는 제품의 경우, 양산 중이 ㄴ공정에서 필요한 데이터를 확보하기 쉽지 않음\n",
    "     - 불량률이 0.1% 이하로 매우 낮은 제품군의 경우에는 다양한 불량품 데이터를 제공받기 매우 어려움\n",
    "     - 수 많은 양산 데이터가 있더라도 잘 분류된 정답 label을 포함한 질 좋은 데이터는 확보가 어려움\n",
    "     \n",
    "### 딥러닝 적용의 해결방법 및 근거\n",
    "- Domain Knowledge의 활용하여\n",
    "    - End-to-end문제가 아닌 할 수 있는 최대한의 전처리는 모두 다 해주고, 최대한 학습하기 좋은 형태로 데이터를 가공, \n",
    "    - 출력도 최종 출력을 한번에 뽑아내려 하지 말고, 중간의 출력에 Domain Knowledge를 이용한 알고리즘을 한 번 더 적용한다. \n",
    "    - 딥러닝의 관심적인 모델이 아닌, 데이터와 현상에 기반한 적합한 well-defined모델을 이용하여 문제를 해결한다.\n",
    "    - 무조건 많은 데이터가 아닌 섬세하게 확보한 적정 수준의 데이터를 이용하여 목적을 달성 할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공정 분석 딥러닝 실무\n",
    "#### 그래서 이번 학습에서는 가상고객 한 분을 설정해서, 그 가상 고객과 커뮤니케이션하면서 공동으로 원하는 무언가를 만들어보고자 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 딥러닝 실무 개요\n",
    "#### 1) 문제 정의하기 2) 스펙 결정하기  3) 실행 가능성 확인하기  4) 알고리즘 설계하기  5) 데이터 정리하기  6) 모델 학습 및 검증하기 7) 프로그램 전달하기\n",
    "## 2. 가상의 고객 설정\n",
    ": 고객이란 누구를 말하는 걸까? 누구를 위해 일하느냐는 매우 중요하다. 고객의 '요구 사항'을 만족해야 하기 때문이다. \n",
    "\n",
    "가상고객 \n",
    "이름 : 정현정 \n",
    "특징 : - 원단 사업부 제조 공정 엔지니어\n",
    "        - 제조 통계에 익숙하며, 인공지능 도입은 처음\n",
    "        - 원단에 대한 도메인 지식이 뛰어남\n",
    "        - 제조 공정에 자주 드나들어 연락이 어려움\n",
    "## 3. 데이터셋\n",
    ": 최근 aitex 사 에서 공개한 Fabric Image Dataset을 사용한다. 데이터셋을 상황에 맞게 조작한 것을 사용할 것이다. http://www.aitex.es/afid\n",
    "** 압출 풀 시 : https://www.fonedog.com/ko/powermymac/how-to-open-7z-files-on-mac.html 참고\n",
    "\n",
    "출처  : AFID: a  public fabric image database for defect detection.\n",
    "Javier Silvestre-Blanes, Teresa Albero-Albero, Ignacio Miralles, Rubén Pérez-Llorens, Jorge Moreno\n",
    "AUTEX Research Journal, No. 4, 2019   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #computer vision library\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DEFECT = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/Defect_images/'\n",
    "PATH_MASK = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/Mask_images/'\n",
    "PATH_NODEFECT = '/Users/jeonghyeonjeong/for github/머신러닝_데이터분석A-Z_패스트캠퍼스/의류직물 분량 검출을 위한 이미지 분석/dataset/NODefect_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)#동일한 결과를 얻을 수 있게 random.seed를 고정\n",
    "\n",
    "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
    "#if not defect_list :\n",
    "    #print('defect_list is empty!')\n",
    "mask_list = glob.glob(PATH_MASK + '*.png')\n",
    "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
    "\n",
    "#defect, mask 데이터를 쌍으로 묶어주는 작업을 진행\n",
    "new_defect_list = list()\n",
    "new_mask_list = list()\n",
    "for defect in defect_list:\n",
    "    num = defect.split('/')[-1].split('_')[0]\n",
    "    for mask in mask_list:\n",
    "        num_mask = mask.split('/')[-1].split('_')[0]\n",
    "        if num == num_mask:\n",
    "            new_defect_list.append(defect)\n",
    "            new_mask_list.append(mask)\n",
    "            break\n",
    "defect_list = new_defect_list\n",
    "mask_list = new_mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 발송 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set을 진행하면서 여러번 데이터를 취득하게 될 텐데 데이터를 얻는 과정을 나누어보면\n",
    "#The first dataset given\n",
    "if os.path.exists('dataset/1') is False:\n",
    "    os.mkdir('dataset/1')\n",
    "for file_name in pass_list + defect_list:\n",
    "    if random.randint(0, 9) < 2:\n",
    "        barcode = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "        shutil.copy2(file_name, 'dataset/1/' + barcode + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 번째 데이터 생생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second dataset\n",
    "if os.path.exists('dataset/2') is False: \n",
    "    os.mkdir('dataset/2')\n",
    "if os.path.exists('dataset/2/OK') is False:\n",
    "    os.mkdir('dataset/2/OK')\n",
    "if os.path.exists('dataset/2/FAIL') is False:\n",
    "    os.mkdir('dataset/2/FAIL')\n",
    "    \n",
    "idx = 0\n",
    "\n",
    "for file_name in pass_list: #pass_list = glob.glob(PATH_NODEFECT + '*.png')의 이미지를 하나씩 \n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height//2\n",
    "    \n",
    "    for i in range(width//step):\n",
    "        w = i * step\n",
    "        if w<width - height and random.randint(0, 9) <2:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/2/OK/%04d.png' % idx,patch)\n",
    "            idx += 1\n",
    "            \n",
    "patch_list = list()\n",
    "for item in zip(defect_list, mask_list): #그 다음은 defect_list와 mask_list \n",
    "    defect, mask =item\n",
    "    \n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "    \n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    \n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_list.append(patch)\n",
    "\n",
    "random.shuffle(patch_list)\n",
    "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
    "for idx, patch in enumerate(patch_list_fraction):\n",
    "    cv2.imwrite('dataset/2/FAIL/%04d.png' % idx, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세 번째 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third dataset\n",
    "if os.path.exists('dataset/3') is False:\n",
    "    os.mkdir('dataset/3')\n",
    "if os.path.exists('dataset/3/OK') is False:\n",
    "    os.mkdir('dataset/3/OK')\n",
    "if os.path.exists('dataset/3/FAIL') is False:\n",
    "    os.mkdir('dataset/3/FAIL')\n",
    "if os.path.exists('dataset/3/MASK') is False:\n",
    "    os.mkdir('dataset/3/MASK')\n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 3:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/3/OK/%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/3/FAIL/%04d.png' % idx, patch)\n",
    "    cv2.imwrite('dataset/3/MASK/%04d.png' % idx, patch_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실전 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test dataset\n",
    "if os.path.exists('dataset/input_data') is False:\n",
    "    os.mkdir('dataset/input_data')\n",
    "if os.path.exists('dataset/output_csv') is False:\n",
    "    os.mkdir('dataset/output_csv')\n",
    "    \n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 5:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/input_data/ok_%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/input_data/fail_%04d.png' % idx, patch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 요구 사항 분석(Requirements analysis)\n",
    ": 요구 사항 분석은 매우 중요하며, 경영학과 소프트웨어 공학에서 깊게 다룬다. \n",
    "### 고객의 요구사항\n",
    "   고객 요구사항을 끌어내는 것(Requirements gathering)의 실패 사례)\n",
    "        - A : 정현정님 안녕하세요? 제가 어떤 것을 해 드리면 되나요?\n",
    "        - C : 안녕하세요, 인공지능 전문가라고 하셨죠? 뭘 해 주실 수 있나요?\n",
    "        - A : 어.. 영상 분석이니까 CNN으로 Classification을 해드릴 수 있을 것 같은데요..\n",
    "        - C : 영상이 아니라 사진이고요, CNN?? 클래시..뭐요?\n",
    "   성공 사례)\n",
    "       고객의 목소리(VOC; Voice of Customer)\n",
    "       - C : 직조를 하고 나면 검사 공정에서 사진을 찍는데, 지금은 사람이 보고 거릅니다. \n",
    "           공정 검사가 자동으로 됐으면 좋겠습니다. \n",
    "           인공지능이 알아서 불량인지 정상인지 엑셀에 써주면 좋겠습니다. \n",
    "           왜 불량인지도 알면 좋겠는데, 이건 아무래도 어렵겠죠?\n",
    "\n",
    "## 5. 결과물로 이야기하라. \n",
    ": 고객에게 완벽한 결과물만 보여줘야 하는 것이 아니다. 결과물 예시를 프로토타입하고, 중간 결과를 보여주어라. **눈에 보이는 실체를 가지고 이야기해야 아이디어가 나오고, 개선점을 찾을 수 있다.**\n",
    "        - A : 이미지 분석으로는 이렇게 검출, 분할, 분류를 할 수 있습니다. *용어도 쉽게 바꿈*\n",
    "        - C : 좋습니다. 불량인지 아닌지 분류만 해 줘도 유용하겠네요. \n",
    "        \n",
    "## *. 최종 업무 노트 현황\n",
    "        A : 최종으로는 ,Classifier학습하기와 Excel입력 자동화 하기를 하면 되겠다. \n",
    " \n",
    "## 6. 상세 스펙 결정하기(Specification)\n",
    ": 개발 할 때 어떻게 동작해야 하는지 그것을 상세하게 나열한 것을 말한다.  스펙을 결정하고 문서화하는 것은  매우 중요하다. 스펙은 업무 산출물의 유효성을 결정하기 때문이다. \n",
    "- 지원 환경\n",
    "- 프로그램 동작 속도\n",
    "- 알고리즘 성능(정확도, 정밀도, 재현성..)\n",
    "    : 무조건 정확도만 높은 것 보다는, 재현율과 정밀성 사이에서 Trade-off를 따져 보아야 한다.\n",
    "    **정밀도** : 검출한 것 중에 얼마나 많이 불량인가?\n",
    "    **재현성** : 전체에서 불량을 얼마나 많이 찾았는가?\n",
    "- 검출 가능한 최소 불량 영역 크기 등\n",
    "\n",
    "        \n",
    "## *. 최종 업무 노트 현황\n",
    "        A : - Classifier학습하기\n",
    "             - Excel 입력 자동화하기\n",
    "             - Test용 프로그램 작성하기\n",
    "             - 미검이 없도록 알고리즘 튜닝\n",
    "             - GPU환경에서 실시간 동작 확인\n",
    "\n",
    "## 7. 실행 가능성 확인하기\n",
    "### 데이터 요청\n",
    "- 여기선 앞에서 dataset/1 에 저장해 둔 데이터를 요청답안으로 받았다고 생각하고 이용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20 #이정도로 학습 시작\n",
    "\n",
    "DATASET_PATH = 'dataset/2/'\n",
    "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'  #정상\n",
    "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png' #불량\n",
    "\n",
    "RESULT_SAVE_PATH = 'results/' #알고리즘 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name) : #파일 이름으로 접근 했을 때 파일 이름으로부터 이미지를 불러오고, 그 png로 저장된 이미지를 256*256*3으로 decoding해주는 함수\n",
    "    img = tf.io.read_file(file_name)\n",
    "    img = tf.image.decode_png(img)\n",
    "    return tf.image.convert_image_dtype(img, tf.float32) #convert_image_dtype이란 함수를 사용하면 읽어 올 때는 int 인데 float로 변형을 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob을 이용하면 (glob.glob) 폴더 안의 패턴으로 되어있는 파일을 리스트 형태로 파일 이름을 정리해 준다. \n",
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "#print(ok_list) #리스트 형태로 정리 된 것을 확인 할 수 있다. \n",
    "\n",
    "#OK에 대한 데이터 셋 만들기\n",
    "ds_ok  = tf.data.Dataset.list_files(ok_list) #이 ok_list에 있는 파일 들을 불러올 수 있다. \n",
    "\n",
    "#OK에 대한 레이블 만들어 주기\n",
    "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
    "\n",
    "#ok_ds 완성\n",
    "ds_ok = ds_ok.map(preprocess) #mapping : ds_ok에서 iterative하게 나오는 데이터들, 즉 file_name이 map의 매개변수에 있는 preprocess를 거쳐서 리턴되는 것으로 다시 바꿔주게 된다. \n",
    "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label)) #zip : label도 같이 출력되게 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAIL 도 앞의 OK와 같게 데이터셋을 만들어 준다. \n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
    "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
    "\n",
    "ds_fail = ds_fail.map(preprocess)\n",
    "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이제 OK 데이터셋과 FAIL 데이터 셋을 합쳐준다. (concatnate 이용)\n",
    "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋의 크기를 알지 못하니까 \n",
    "#ds_size = 0\n",
    "#for _ in ds:\n",
    "   #ds_size +=1 #이렇게 사이즈를 알아낼 수 있다. \n",
    "#그런데 지금은 리스트 형식이기 때문에 보다 간단하게 \n",
    "ds_size = len(ok_list) + len(fail_list)\n",
    "\n",
    "#이중 70%는 Train, 30%는 Test case로 쓰도록 하자. \n",
    "train_size = int(ds_size *0.7)\n",
    "\n",
    "#shuffle을 이용해서 전체 데이터셋을 잘 섞어준다. \n",
    "ds = ds.shuffle(ds_size)\n",
    "\n",
    "#train데이터 셋을 take를 이용해서 전체 크기 만큼의 70% 즉, train_size 만큼 가져오도록 한다. \n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration = True).batch(32)\n",
    "ds_test = ds.skip(train_size).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 및 학습 : CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    return Sequential ([Conv2D(32, (3, 3), activation = 'relu'), \n",
    "                                    MaxPool2D(),\n",
    "                       Conv2D(64, (3, 3), activation = 'relu'), \n",
    "                                    MaxPool2D(),\n",
    "                       Conv2D(128, (3, 3), activation = 'relu'), \n",
    "                                    MaxPool2D(),\n",
    "                       Conv2D(256, (3, 3), activation = 'relu'), \n",
    "                                    MaxPool2D(),\n",
    "                       Flatten(), \n",
    "                       Dense(1, activation = 'sigmoid')]) #binary classification이니까 sigmoid 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'binary_crossentropy', \n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 66s 3s/step - loss: 0.3905 - accuracy: 0.8437 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 59s 3s/step - loss: 0.3427 - accuracy: 0.8879 - val_loss: 0.3969 - val_accuracy: 0.8797\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 63s 3s/step - loss: 0.3213 - accuracy: 0.8894 - val_loss: 0.3598 - val_accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 58s 3s/step - loss: 0.4567 - accuracy: 0.8510 - val_loss: 0.3355 - val_accuracy: 0.9038\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 57s 3s/step - loss: 0.3282 - accuracy: 0.8909 - val_loss: 0.3398 - val_accuracy: 0.8935\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 58s 3s/step - loss: 0.3571 - accuracy: 0.8673 - val_loss: 0.3394 - val_accuracy: 0.8522\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 62s 3s/step - loss: 0.3032 - accuracy: 0.8997 - val_loss: 0.4057 - val_accuracy: 0.8900\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 58s 3s/step - loss: 0.3466 - accuracy: 0.8850 - val_loss: 0.2922 - val_accuracy: 0.8969\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 57s 3s/step - loss: 0.3244 - accuracy: 0.8805 - val_loss: 0.3299 - val_accuracy: 0.8797\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 55s 3s/step - loss: 0.3127 - accuracy: 0.8820 - val_loss: 0.2845 - val_accuracy: 0.8900\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 57s 3s/step - loss: 0.3088 - accuracy: 0.8850 - val_loss: 0.3442 - val_accuracy: 0.8591\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 55s 2s/step - loss: 0.3355 - accuracy: 0.8761 - val_loss: 0.2756 - val_accuracy: 0.8900\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 59s 3s/step - loss: 0.3142 - accuracy: 0.8938 - val_loss: 0.3238 - val_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 54s 2s/step - loss: 0.3170 - accuracy: 0.8717 - val_loss: 0.2929 - val_accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 56s 3s/step - loss: 0.3198 - accuracy: 0.8746 - val_loss: 0.3118 - val_accuracy: 0.8763\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 52s 2s/step - loss: 0.3147 - accuracy: 0.8746 - val_loss: 0.3299 - val_accuracy: 0.8832\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 56s 3s/step - loss: 0.3462 - accuracy: 0.8761 - val_loss: 0.3302 - val_accuracy: 0.8797\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 51s 2s/step - loss: 0.3215 - accuracy: 0.8776 - val_loss: 0.2546 - val_accuracy: 0.8866\n",
      "Epoch 19/20\n",
      "13/22 [================>.............] - ETA: 18s - loss: 0.3276 - accuracy: 0.8894"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data = ds_test, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과를 이미지로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과를 이미지로 저장할 폴더들을 만들어 줄 것\n",
    "#if os.path.exists(RESULT_SAVE_PATH) is False:\n",
    "  #  os.mkdir(RESULT_SAVE_PATH)\n",
    "#근데 매번 이렇게 만들어주기가 번거로우니까 함수로 만들어준다. \n",
    "\n",
    "def mkdir(path) : \n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "        \n",
    "mkdir(RESULT_SAVE_PATH)\n",
    "mkdir(RESULT_SAVE_PATH + '/TRUEPOSITIVE')\n",
    "mkdir(RESULT_SAVE_PATH + '/TRUENEGATIVE')\n",
    "mkdir(RESULT_SAVE_PATH + '/FALSEPOSITIVE')\n",
    "mkdir(RESULT_SAVE_PATH + '/FALSENEGATIVE')\n",
    "\n",
    "index = 0\n",
    "for imgs, labels in ds_test:\n",
    "    preds  = model.predict(imgs) #model의 predict함수를 이용해서 결과를 뽑아준다. \n",
    "    for idx in range(imgs, shape[0]):\n",
    "        groundtruth = labels[idx].numpy()\n",
    "        y = preds[idx]\n",
    "        if groundtruth == 1 and y > 0.5 : ##정답이 1이고, binary classification이니까 0.5\n",
    "            path = RESULT_SAVE_PATH + '/TRUEPOSITIVE'\n",
    "        elif groundtruth ==1 and y <=0.5 :\n",
    "            path = RESULT_SAVE_PATH + '/FALSENEGATIVE'\n",
    "        elif groundtruth == 0 and y>0.5 :\n",
    "            path = RESULT_SAVE_PATH + '/FALSEPOSITIVE'\n",
    "        else :\n",
    "            path = RESULT_SAVE_PATH + '/TRUENEGATIVE'\n",
    "        cv2.imwrite(path + '/%.f_%04d.png' % (y, index), imgs[idx].numpy()*255)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
